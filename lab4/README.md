# 4th Lab Exercise: Exercise for High Level Synthesis on FPGA

## Lab Overview

The goal of this lab is to study **FPGA programming** with **High Level Synthesis (HLS)**. Specifically, the lab focuses on optimizing and accelerating C code for deployment on the **Xilinx Zybo FPGA**. The application being optimized relates to **Generative Adversarial Networks (GANs)**, and the task is to accelerate the GAN algorithm for image reconstruction from incomplete handwritten digits (from the MNIST dataset). 

The objective is to maximize the **speedup** between the software (SW) and hardware (HW) implementations of the GAN algorithm, by applying HLS optimizations to the hardware portion of the computation.

## Environment

This solution was specifically developed and tested in the **Xilinx SDSoC 2016.4** environment. For best results, the code should be used and tested in the same version.

### Required Tools:
- **Xilinx SDSoC 2016.4:** Development environment for FPGA programming with HLS.
- **Zybo FPGA:** Hardware platform used for deploying the optimized system.
- **Jupyter Notebook** or **Google Colab:** For visualizing the image reconstruction output.

You can find detailed installation and setup instructions in the following guides:
- [Lab4.pdf](https://github.com/PanosMpel/Embedded-Systems-NTUA/blob/main/lab4/Lab4.pdf)

## Repository Contents

1. **Original Code:**  
   The initial version of the code before applying any changes. This version is used for **Exercise 1: Performance and Resource Measurement**.

2. **Modified Code:**  
   The version of the code that includes necessary optimizations. This updated version is also used for **Exercise 1: Performance and Resource Measurement**.

3. **Data:**  
   A zipped folder containing the dataset used for training and testing the implemented algorithms.

4. **Outputs:**  
   Contains the output files generated from different runs of the exercises.

5. **[Lab4.pdf](https://github.com/PanosMpel/Embedded-Systems-NTUA/blob/main/lab4/Lab4.pdf):**  
   A detailed document with step-by-step instructions for completing the exercises.

6. **`ipynb checkpoints` Folder:**  
   Includes Jupyter Notebook checkpoints for **Exercise 2: Quality Measurement**.

## Task Overview

### Task 1: Performance and Resources Measurement

-   Set the `forward_propagation` function as a **hardware function** and estimate performance without applying any optimizations. Record the **estimated resources** and **cycles** for the hardware function.
-   Generate the **SD card** with the bitstream and load it onto the Zybo. After rebooting, run the application on the board. Measure how many cycles it takes to execute. Does this agree with the estimation? What is the **speedup** compared to the software execution on the ARM?
-   Perform **design space exploration** to apply optimizations and speed up the algorithm. Try different **HLS pragmas** and evaluate the **estimated performance**. After making improvements, regenerate the SD card with the new bitstream, then test on the Zybo. Compare the new results with the unoptimized version in terms of cycles and speedup.
-   Check the **HLS report** for the optimized implementation in SDSoC. Record the **latency details** for each loop. Which layer has the highest latency? Is the design fully pipelined? In the **Resource Profile** section of the HLS report, list the types of mathematical expressions used. Which expression requires the most DSPs?

### Task 2: Quality Measurement

-   Transfer the **output.txt** generated by the Zybo to your PC and run it using the provided **Jupyter notebook** (`plot_output.ipynb`). Display the combined images from **software (SW)** and **hardware (HW)** for specific numbers (e.g., `idx=10`, `idx=11`, `idx=12`).
-   The implementation uses **8-bit decimal precision** for the data types. To modify this, change the **BITS** and **BITS_EXP** parameters in the `network.h` file, where **BITS_EXP=2(BITS+2)** (e.g., set `BITS=6`, `BITS_EXP=256` for 6-bit precision). Replace the pre-computed values of **Tanh** in `tanh.h` with the appropriate values for the chosen bit precision. After adjusting, create new designs with **4-bit** and **10-bit** precision and run them. Display the results and compare the image quality.
-   Measure the **image reconstruction quality** for different bit precisions (e.g., 4, 8, 10 bits) using the provided Jupyter notebook. For each bit precision, compute the **max pixel error** and **Peak Signal-to-Noise Ratio (PSNR)**. Which precision gives the best quality for you, and why?

---

 
